Bienvenido a la semana 2. Esta semana, profundizará en el ciclo de vida y las corrientes subyacentes de la ingeniería de datos, que presentamos la semana anterior. Como vio en la semana 1, el ciclo de vida comienza con la generación de datos a partir de los sistemas de origen, aquí a la izquierda, que es realmente una etapa que ocurre antes de que comience su trabajo como ingeniero de datos. A continuación, analizaremos la ingestión, la transformación, el almacenamiento y la entrega de datos para múltiples casos de uso, como el análisis y el aprendizaje automático. O, en términos más sencillos, analizaremos cómo, en su trabajo como ingeniero de datos, trabajará para obtener datos sin procesar de algún lugar, convertirlos en algo útil y, luego, ponerlos a disposición para casos de uso posteriores. En la segunda lección de esta semana, analizaremos las corrientes subyacentes del ciclo de vida de la ingeniería de datos, la seguridad, la administración de datos, las operaciones de datos, la arquitectura de datos, la orquestación y la ingeniería de software. Ahora, para que quede claro, quiero hacer hincapié en que esta semana, al igual que la semana anterior de materiales, se centra más en un marco mental de alto nivel para la ingeniería de datos que en construir realmente una infraestructura de datos. Esto se debe a que creo que es muy importante establecer ese marco mental antes de empezar a construir. Esto hará que tenga más éxito en todos los aspectos de su trabajo como ingeniero de datos. Pero dicho esto, esta semana no se trata solo de teoría. Al final de la semana, analizaremos cómo se combina este marco mental en la práctica en la nube de AWS. En la actividad de laboratorio, trabajará con su primera canalización de datos en la nube de extremo a extremo. Acompáñeme en el siguiente vídeo para empezar por analizar los sistemas de generación y fuente de datos.

La primera etapa del ciclo de vida de la ingeniería de datos es la generación de datos y sistemas fuente. En su función como ingeniero de datos, consumirá datos de varias fuentes. Por ejemplo, si trabajas en una empresa de comercio electrónico, puedes crear una canalización de datos que consuma los datos de las transacciones de ventas de una base de datos de ventas interna y los datos del catálogo de productos de los archivos. Es posible que el equipo de marketing necesite que obtengas datos de redes sociales de una API y conjuntos de datos de investigación de mercado de una plataforma de intercambio de datos. Es posible que incluso te encuentres trabajando con datos de dispositivos de Internet de las cosas o IoT, como rastreadores GPS para recopilar datos de ubicación y movimiento para actualizar la entrega de productos. Estos sistemas suelen ser creados y mantenidos por otros equipos, incluidos ingenieros de software de otros departamentos internos, proveedores externos o plataformas de terceros. Como ingeniero de datos, están en gran medida fuera de su control. Sin embargo, es importante entender cómo funcionan estos sistemas, ya que las canalizaciones de datos que cree dependerán de los datos generados a partir de estas fuentes. Comencemos por analizar más de cerca algunos de los sistemas fuente comunes con los que trabajará como ingeniero de datos. Los sistemas fuente más comunes son las bases de datos, que pueden ser bases de datos relacionales, representadas como tablas de datos relacionados, como puede ver aquí, u otros tipos de sistemas NoSQL, incluidos elementos como bases de datos de valores clave , almacenes de documentos y más. Estas bases de datos pueden formar parte del back-end de una aplicación web o móvil, o puede que estés almacenando datos de algún otro sistema, y no te preocupes si aún no estás familiarizado con otros tipos de bases de datos. Entraremos en los detalles de las bases de datos más adelante. Además de los sistemas fuente de bases de datos, es posible que también esté consumiendo datos en forma de archivos, como archivos de texto, archivos de audio como MP3 o incluso archivos de vídeo u otros tipos de archivos. Si bien es posible que los archivos individuales como estos no parezcan algo que se pueda llamar un sistema fuente, descubrirá que, en muchos casos, en su trabajo como ingeniero de datos, necesita descargar archivos o tener acceso a ellos para comenzar a trabajar. Otro sistema fuente común que encontrará como ingeniero de datos es una API, que es la abreviatura de interfaz de programación de aplicaciones. En pocas palabras, una API te permite emitir una solicitud web de datos y luego recuperarlos en un formato determinado, como XML o JSON. También puede obtener datos a través de una plataforma de intercambio, que es algo que las organizaciones pueden configurar para compartir datos internamente o con un tercero. Los dispositivos de IoT, como mencioné anteriormente, representan otro tipo de sistema fuente que se está volviendo cada vez más común. Con este tipo de sistema fuente, es posible que tenga muchos dispositivos individuales, lo que se conoce como un enjambre de dispositivos de IoT, que transmiten datos en tiempo real. Estos datos de transmisión generalmente se envían a una base de datos, y el propietario del sistema de origen puede hacer que esos datos sean accesibles a través de una API o una plataforma de intercambio de datos. En otros casos, es posible que necesite ingerir y combinar todos esos flujos de datos individuales para usarlos en sus propios flujos de trabajo posteriores. En un mundo perfecto, los sistemas de origen de los que depende proporcionarían los datos que necesita de manera coherente y oportuna, de modo que podría crear sistemas posteriores que se basen en la previsibilidad de ese sistema de origen. Sin embargo, en el mundo real, los sistemas fuente son impredecibles. A veces, estos sistemas dejan de funcionar o el equipo que administra el sistema cambia el formato o el esquema de los datos, o tal vez el esquema permanece igual, pero los datos en sí cambian. Cuando empecé a trabajar como ingeniero de datos, recuerdo haber trabajado con una base de datos mantenida por un equipo interno de ingenieros de software. Un día, ese equipo decidió reorganizar las columnas de la base de datos de su aplicación y no me informó de estos cambios. Descubrí que las columnas en las que se basaban mis canalizaciones de datos habían cambiado, se les había cambiado el nombre y algunas de ellas incluso se habían eliminado. Esto interrumpió por completo algunos de los flujos de trabajo de datos posteriores y tuve que responder a algunas partes interesadas bastante molestas, así que no fue bueno. Al acceder a los datos de los sistemas de origen, es fundamental comprender cómo están configurados esos sistemas y qué cambios se pueden esperar en los datos o el sistema. Esto significa que, como ingeniero de datos, tendrá más éxito si trabaja directamente con los propietarios de los sistemas de origen para comprender cómo funcionan esos sistemas, cómo generan datos, cómo esos datos pueden estar sujetos a cambios con el tiempo y, en última instancia, cómo afectarán esos cambios a los sistemas posteriores que construya. Según mi experiencia, desarrollar buenas relaciones de trabajo con las partes interesadas de los sistemas fuente es una parte subestimada pero crucial del éxito de la ingeniería de datos. Dependiendo de sus sistemas de origen y de sus objetivos, la siguiente fase importante del ciclo de vida de la ingeniería de datos, la ingestión puede ser muy diferente de un proyecto a otro. Acompáñeme en el siguiente vídeo para ver la ingestión desde los sistemas fuente.

Como ingeniero de datos, construirá arquitecturas que comiencen con el paso de ingerir datos de los sistemas de origen, lo que significa mover los datos sin procesar de los sistemas de origen a su canalización de datos para su posterior procesamiento. Según mi experiencia, los sistemas de origen y la ingestión de datos representan los mayores obstáculos del ciclo de vida de la ingeniería de datos. Si empezaste, como recomendé en el vídeo anterior, por trabajar directamente con los propietarios de los sistemas de origen para entender cómo funcionan esos sistemas, cómo generan los datos, cómo esos datos pueden estar sujetos a cambios con el tiempo y, en última instancia, cómo afectarán esos cambios a los sistemas posteriores que construyas. Entonces estarás en una buena posición para evitar los errores más comunes en la fase de ingestión. Una de las decisiones fundamentales que debe tomar al diseñar los procesos de ingesta de datos es la frecuencia con la que necesita ingerir los datos, es decir, la frecuencia con la que debe mover los datos de estos sistemas de origen que se muestran aquí a la izquierda, a su canalización de datos para su posterior procesamiento. Puedes elegir ingerir los datos de vez en cuando en lotes, por ejemplo, una vez cada hora o una vez al día. Otro enfoque que se está volviendo cada vez más común es ingerir datos como un flujo constante de eventos casi en tiempo real. En este vídeo, me centraré en presentar estos dos patrones principales de ingesta de datos, por lotes o por streaming. Puede pensar en los datos que se producen como una serie continua de eventos. Estos eventos pueden ser clics en un sitio web, mediciones de sensores u otra cosa. En el mundo, eventos como estos ocurren continuamente. En cierto sentido, se podría pensar que casi todos los datos se transmiten en su origen. La ingestión de lotes es solo una forma cómoda de procesar el flujo de eventos en grandes porciones, ya sea en un intervalo de tiempo predeterminado o cuando los datos alcanzan un umbral de tamaño preestablecido. Por ejemplo, puede gestionar los datos de un día entero en un solo lote. Durante mucho tiempo, el procesamiento por lotes fue la forma predeterminada de ingerir datos. Hoy en día hay más opciones de ingestión. El procesamiento por lotes sigue siendo una forma práctica y popular de ingerir datos, especialmente en los casos en que los datos se utilizan en análisis y aprendizaje automático. Con la ingestión de streaming, por otro lado, se ingieren y proporcionan datos a los sistemas posteriores de forma continua y casi en tiempo real. Ahora, cuando digo que estás ingiriendo datos y casi en tiempo real, me refiero a que los pones a disposición de los sistemas posteriores poco tiempo después de su producción. Posiblemente menos de un segundo después. En este caso, debe usar herramientas específicas, como una plataforma de transmisión de eventos o una cola de mensajes para ingerir flujos de eventos de forma continua. Con estas herramientas cada vez más omnipresentes, la ingestión de streaming se ha vuelto más accesible y popular. Sin embargo, la ingestión de streaming no es necesariamente la mejor opción para todos los casos de uso y hay que tener en cuenta importantes desventajas a la hora de decidir si la ingestión de streaming es una opción adecuada en lugar de lo que podría considerarse el enfoque más simple de la ingestión por lotes. Si está trabajando en una solución de procesamiento de transmisiones, debería preguntarse: ¿qué acciones puede tomar con los datos en tiempo real que serían una mejora con respecto a los datos por lotes? ¿ La ingestión de streaming costaría más que el lote en términos de tiempo, dinero, mantenimiento y posibles tiempos de inactividad? ¿Cómo influirá la ingestión de transmisiones en lugar de la ingesta de lotes o viceversa en el resto de su canalización de datos? La ingestión por lotes es un enfoque excelente para muchos casos de uso comunes, como la negociación de modelos y los informes semanales. Mi consejo es que adoptes un sistema de ingesta de streaming solo después de que te hayas tomado el tiempo de identificar un caso de uso empresarial que justifique las desventajas de usarlo por lotes. También es importante tener en cuenta que la ingesta de streaming generalmente coexiste con el procesamiento por lotes. Por ejemplo, los modelos de aprendizaje automático suelen entrenarse por lotes. Sin embargo, es posible que esos mismos datos de entrenamiento se hayan ingerido originalmente mediante streaming debido a algún objetivo diferente de su arquitectura, como la detección de anomalías en tiempo real. En raras ocasiones, los ingenieros de datos tienen la opción de crear una canalización de datos exclusivamente de streaming sin componentes por lotes. En su lugar, elegirás dónde se establecerán los límites entre el lote y la transmisión. Más allá de decidir entre un enfoque por lotes o un enfoque de streaming, hay otros matices importantes en la etapa de la ingestión, como la forma en que se puede utilizar la captura de datos cambiados o CDC, por sus siglas en inglés, para activar ciertos procesos de ingestión en función de los cambios en los datos en el sistema de origen , y si se adoptará un enfoque de empuje o extracción, es decir, si un sistema de origen le enviará datos o si los extraerá activamente de la fuente. Analizaremos todos estos detalles y más a lo largo de la especialización. Pero por ahora, acompáñeme en el siguiente vídeo para ver el almacenamiento de datos, que en realidad forma parte de cada etapa del ciclo de vida de la ingeniería de datos.

Me gustaría que pensara por un momento en las diferentes formas en que interactúa con los sistemas de almacenamiento de datos a diario. En su portátil, por ejemplo, puede crear o eliminar archivos o mover archivos de una carpeta a otra. De este modo, cambiarás la forma en que se almacenan las cosas en el disco duro o en la unidad de estado sólido. Cuando abres aplicaciones, las cargas en una memoria de acceso aleatorio o RAM, que es simplemente otro tipo de almacenamiento que permite un acceso más rápido, o puedes descargar nuevos archivos o aplicaciones de Internet o hacer copias de seguridad automáticas de algunos de tus archivos en el almacenamiento en la nube. También con su teléfono inteligente, puede enviar o recibir mensajes o interactuar con aplicaciones, lo que permite mover datos de manera efectiva entre los diferentes componentes de almacenamiento de su dispositivo y en la nube. Con casi cualquier acción que realices en un dispositivo digital o en línea, interactúas con los sistemas de almacenamiento de datos y es posible que te encuentres con los límites de los sistemas de almacenamiento, como quedarte sin espacio para almacenar imágenes en el teléfono o intentar enviar archivos demasiado grandes. La función, el rendimiento y las limitaciones que encuentre tendrán mucho que ver con la configuración de esos sistemas. Del mismo modo, en su trabajo como ingeniero de datos, la función, el rendimiento y las limitaciones de los sistemas que cree tendrán mucho que ver con las soluciones de almacenamiento que elija para dar soporte a esos sistemas. Para empezar, echemos un vistazo a algunos de los ingredientes básicos del hardware del almacenamiento. En su vida cotidiana, es probable que se haya familiarizado con diversas formas de almacenamiento de estado sólido, como las tarjetas de memoria flash o las unidades de estado sólido, su computadora portátil o su teléfono inteligente. Por el contrario, es probable que no haya leído datos de un disquete recientemente. Se le podría perdonar por pensar que el mundo ha dejado los discos magnéticos como solución de almacenamiento de datos. Sin embargo, la verdad es que los discos magnéticos siguen siendo la columna vertebral de los sistemas de almacenamiento modernos, y eso se debe principalmente al bajo costo del almacenamiento en disco. En el momento de esta grabación, el almacenamiento en disco es entre 2 y 3 veces más barato que el almacenamiento en estado sólido. La RAM, comúnmente conocida como memoria, es otra forma de almacenamiento físico con la que quizás esté familiarizado. La RAM ofrece velocidades de lectura y escritura mucho más rápidas y unidades o discos de estado sólido, lo que la convierte en un componente fundamental de muchas aplicaciones y arquitecturas. Sin embargo, el almacenamiento en RAM podría ser entre 30 y 50 veces más caro que el almacenamiento de estado sólido. También es volátil en el sentido de que si el sistema pierde energía, la mayoría de las veces, según el tipo de RAM que utilice, la memoria se pierde al instante. En la mayoría de las arquitecturas modernas, los datos pasarán por el almacenamiento magnético, las unidades de estado sólido y la memoria a medida que avanzan por las distintas fases de procesamiento de la canalización [inaudible]. Sin embargo, los componentes físicos del almacenamiento son solo un aspecto de cómo se implementa el almacenamiento de datos en toda la arquitectura. Los sistemas de almacenamiento de datos modernos y en la nube suelen distribuirse en varios clústeres y centros de datos. Esto significa que aspectos como las redes, la CPU, la serialización, la compresión y el almacenamiento en caché son ingredientes fundamentales para almacenar datos en los sistemas de datos modernos. No te preocupes si no estás familiarizado con todas las cosas que acabo de mencionar. Profundizaremos en los detalles de cada uno de estos elementos del almacenamiento y del tercer curso de la especialización. Como ingeniero de datos, normalmente no serás responsable de administrar los detalles granulares de cómo tus datos se mueven y se almacenan en una red de centros de datos y dispositivos de almacenamiento físico. En su lugar, trabajará con sistemas de almacenamiento como sistemas de administración de bases de datos o plataformas de almacenamiento de objetos como Amazon 3. Según los requisitos de su arquitectura, es posible que también esté trabajando con sistemas como Apache Iceberg o Hoody, sistemas de almacenamiento basados en memoria y caché. O almacenamiento en streaming. Todos estos sistemas de almacenamiento de datos se basan en los ingredientes físicos y otros ingredientes incorrectos del almacenamiento que existen dentro de los servidores y clústeres, lo que permite a estos sistemas ingerir y recuperar datos mediante diferentes protocolos de acceso. Por último, en su trabajo como ingeniero de datos, es probable que no solo trabaje con sistemas de almacenamiento individuales, sino también con combinaciones de sistemas de almacenamiento organizados en abstracciones de almacenamiento, como un almacén de datos, un lago de datos o la combinación más reciente de estos conceptos, la casa del lago de datos. Con las herramientas de abstracción del almacenamiento, en lugar de preocuparse por los detalles de cómo se organizan los componentes subyacentes, elegirá varios parámetros de configuración que le permitirán cumplir los requisitos del sistema en términos de latencia, escalabilidad y costo. Si pensara en el almacenamiento como una jerarquía, ¿cómo organizaría los diferentes aspectos del almacenamiento? Bueno, en el fondo, tenemos los ingredientes básicos del almacenamiento de datos, incluidos los diversos componentes físicos, como el disco, la RAM y el almacenamiento de estado sólido, así como los diversos ingredientes no físicos del almacenamiento, como las redes y la serialización. Además de eso, tiene sistemas de almacenamiento que se crean a partir de estas materias primas, que incluyen sistemas de bases de datos , almacenamiento de objetos y mucho más. Finalmente, en la parte superior de la jerarquía, se encuentran las abstracciones de almacenamiento, que son combinaciones de sistemas de almacenamiento que le permiten satisfacer sus necesidades de almacenamiento de datos de alto nivel sin preocuparse por la mayor cantidad de detalles de bajo nivel. Como ingeniero de datos, es muy posible que dedique gran parte de su tiempo a operar en la parte superior de esta jerarquía o cerca de ella, lo que significa que no tendrá que pensar en los detalles de cómo se mueven exactamente sus datos entre los diferentes componentes y sistemas de almacenamiento. Sin embargo, será más eficaz en su trabajo. Si se toma el tiempo para comprender el funcionamiento interno, las capacidades y las limitaciones de todas sus soluciones de almacenamiento, hasta los ingredientes incorrectos. La verdad es que muchos ingenieros de datos en ejercicio hoy en día no comprenden en profundidad los detalles de los sistemas de almacenamiento que construyen. Esto tiene consecuencias desafortunadas en lo que respecta a aspectos como el rendimiento y el costo. Resulta que una vez fui consultor para un equipo que no tuvo en cuenta estos detalles. Necesitaban trasladar un gran conjunto de datos a su almacén de datos y, sin saberlo, optaron por utilizar el enfoque de insertar filas directamente para cada fila individual de datos, lo que significa que estaban incorporando y escribiendo una fila a la vez en el almacén de datos. Esto resultó no solo muy lento, sino también muy caro, ya que los insertos directos en hileras generalmente se cobran por uso. Al final, descubrieron su error y adoptaron un enfoque de ingestión masiva, pero solo después de haber desperdiciado mucho tiempo y agotado la mitad de su presupuesto anual de almacenamiento de datos en el lapso de una semana. De todos modos, será una ventaja para usted ser un experto en almacenamiento como ingeniero de datos. Por eso, exploraremos los detalles y las implicaciones de las diversas soluciones de almacenamiento a lo largo de estos cursos. A continuación, analizaremos la siguiente etapa del ciclo de vida de la ingeniería de datos: la transformación de datos.

La etapa de transformación del ciclo de vida de la ingeniería de datos es realmente donde usted, como ingeniero de datos, comienza a agregar valor. Esto se debe a que la etapa que precede a la transformación, es decir, la ingesta y el almacenamiento de datos sin procesar de los sistemas de origen, no aporta directamente ningún valor a las partes interesadas posteriores. Como dije antes, en tu rol de ingeniero de datos, el panorama general es que obtienes datos sin procesar de algún lugar, los conviertes en algo útil y luego los pones a disposición de los usuarios finales. La transformación es la etapa de convertirla en algo útil. En términos de lo que es útil, imagine, por ejemplo, a un analista de negocios como usuario intermedio. Supongamos que tienen la tarea de informar sobre las ventas diarias de una gama de productos. Es posible que necesiten información como los identificadores de los clientes , los nombres de los productos, los precios, las cantidades, los tiempos de venta, etc. Si bien los analistas de datos suelen dominar SQL con fluidez, confiarán en usted para transformar los datos sin procesar y proporcionárselos en un formato que sea rápido y fácil de consultar. Como otro ejemplo, imagine a un científico de datos o un ingeniero de aprendizaje automático como usuario intermedio. Además de SQL, es posible que incluso dominen muchos enfoques potenciales para la transformación de datos, pero su función principal consiste realmente en utilizar los datos para el análisis predictivo, y usted puede proporcionarles un enorme valor gestionando la transformación de los datos en estructuras y funciones que se pueden utilizar directamente para el entrenamiento o el análisis de sus modelos. A esta parte del ciclo de vida de la ingeniería de datos la denominamos transformación. Pero, en realidad, el escenario se compone de tres partes : consultas, modelado y transformación. Aquí incluyo las consultas y el modelado como algo independiente de la transformación porque son componentes críticos de cualquier canalización de datos que realmente agregan valor cuando se hacen bien y presentan riesgos cuando se hacen mal. Para ilustrar este punto, comencemos con las consultas. Cuando consultas datos, estás emitiendo una solicitud para leer los registros de una base de datos u otros sistemas de almacenamiento. Por ejemplo, es posible que necesite consultar datos tabulares y semiestructurados que se encuentran en un almacén de datos en la nube. Hay muchos lenguajes que puedes usar para consultar datos, pero en estos cursos, nos centraremos en el lenguaje de consulta estructurado o SQL para abreviar, que sigue siendo un lenguaje de consulta popular y universal. La consulta puede implicar la limpieza, la unión y la agregación de datos de muchos conjuntos de datos. Puede usar expresiones SQL para filtrar los datos de modo que solo se recuperen registros específicos. No se preocupe si aún no está familiarizado con los comandos SQL que ve aquí en la diapositiva. En cursos posteriores, tendrá la oportunidad de aprender los conceptos básicos de SQL a través de laboratorios prácticos. Hay más de una forma de escribir una consulta, y las consultas mal escritas pueden tener consecuencias negativas, como afectar al rendimiento de una base de datos de origen o provocar una situación conocida como explosión de filas, en la que una consulta que incluye lo que se conoce como unión entre tablas produce muchos más registros de los que esperaba, lo que puede hacer caer la infraestructura de almacenamiento. En otras circunstancias, las consultas mal redactadas pueden ralentizarse o generalizarse y provocar retrasos posteriores en los informes o los análisis. En la práctica, resulta que la mayoría de los ingenieros de datos pueden leer y escribir SQL, pero no están familiarizados con el funcionamiento interno de las consultas. Esto puede tener consecuencias imprevistas en las arquitecturas que construyen. En el tercer curso de la especialización, analizaremos exactamente cómo funcionan las consultas. El siguiente tema del que quiero hablar es del modelado de datos. Un modelo de datos representa la forma en que los datos se relacionan con el mundo real. El modelado de datos implica elegir deliberadamente una estructura coherente para los datos y es un paso crucial para hacer que los datos sean útiles para la empresa. Por ejemplo, si volvemos a analizar el caso del analista empresarial que necesita crear informes de ventas de productos, es posible que haya ingerido los denominados datos normalizados de una base de datos fuente relacional ascendente que contiene tablas independientes para cosas como información de productos, detalles de pedidos, información de clientes, etc. Estos datos suelen tener relaciones complejas entre ellos. Para satisfacer las necesidades de este analista, es posible que necesite hacer lo que se denomina desnormalización de estos datos para modelar los datos de manera que los analistas puedan consultar y obtener de manera rápida y eficiente los datos que necesitan para los informes. Un buen modelo de datos está diseñado para reflejar mejor los procesos, las definiciones, los flujos de trabajo y la lógica de su organización. Por ejemplo, el término cliente puede significar cosas diferentes para los distintos departamentos de la empresa. Para tener éxito con el modelado de datos, es necesario trabajar con las partes interesadas para entender su terminología, por ejemplo, lo que la palabra cliente significa para ellas, así como los objetivos empresariales de los datos. Aprenderá más sobre el modelado y la normalización de datos en el cuarto curso de la especialización. Además de consultar y modelar los datos, los datos también deben transformarse, es decir, manipularse, mejorarse y ser seguros para su uso posterior. Como mencioné anteriormente, normalmente transformará los datos varias veces a lo largo del ciclo de vida de la ingeniería de datos. Por ejemplo, los datos pueden transformarse incluso antes de tocarlos (por ejemplo, agregar una marca de tiempo a un registro mientras aún está en un sistema de origen), o puede aplicar transformaciones mientras los datos están en movimiento durante la ingestión e, inmediatamente después de la ingestión, puede configurar transformaciones básicas para asignar los datos a los tipos correctos y colocar los registros en formatos estandarizados. Puede enriquecer un registro dentro de una canalización de streaming con campos y cálculos adicionales antes de enviarlo a un almacén de datos. Incluso más adelante, puede transformar el esquema de datos y aplicar la desnormalización, la agregación a gran escala para la elaboración de informes o los datos destacados para el entrenamiento de modelos de aprendizaje automático. A lo largo de estos cursos, participará en muchos ejercicios prácticos relacionados con la consulta, el modelado y la transformación de datos. Sin embargo, por ahora, pasemos al siguiente vídeo, en el que veremos la etapa final del ciclo de vida de la ingeniería de datos, que sirve de datos para casos de uso posteriores.

Una vez que haya ingerido, transformado y almacenado sus datos, estará listo para la etapa final del ciclo de vida de la ingeniería de datos. Servir datos en esta etapa implica algo más que hacer que los datos estén disponibles. En realidad, es cuando se brinda a las partes interesadas la oportunidad de extraer valor empresarial de los datos. Y como mencioné la semana pasada, el valor significa cosas diferentes para las diferentes partes interesadas. Por lo general, los datos tienen valor cuando se utilizan para casos prácticos de uso final, como el análisis, el aprendizaje automático, la ETL inversa u otros casos de uso. En este vídeo, en lugar de analizar los mecanismos específicos para la entrega de datos, analizaremos brevemente cada uno de estos casos de uso final para ofrecer más contexto sobre cómo la entrega de datos puede tener un aspecto diferente en diferentes escenarios más adelante. En el cuarto curso, analizaremos los detalles de cómo distribuirá exactamente los datos para cada uno de estos casos de uso. Empecemos por la analítica, que es el proceso de identificar información y patrones clave dentro de los datos. Como ingeniero de datos, es casi seguro que entregará datos que impulsen una o más de las tres formas más comunes de análisis: inteligencia empresarial , análisis operativo y análisis integrado. La inteligencia empresarial, o BI para abreviar, es donde los analistas exploran los datos empresariales históricos y actuales para descubrir información. Como ingeniero de datos, entregarás datos que, en última instancia, se presentarán en forma de informes o paneles que ayudan a los usuarios a tomar decisiones estratégicas y procesables. Por ejemplo, los analistas de los equipos de ventas y marketing utilizarán informes y paneles de inteligencia empresarial para detectar patrones y tendencias y supervisar aspectos como la participación de las campañas de marketing, las ventas regionales y las métricas de experiencia del cliente. O imagine un escenario en el que un analista observa un aumento repentino en las devoluciones de productos. Luego, podrían investigar los informes o paneles existentes para comparar este fenómeno con las tendencias históricas. También pueden extraer más datos ejecutando consultas SQL en la base de datos que proporcionaste o pedirte que proporciones datos adicionales para análisis ad hoc. A diferencia de la naturaleza reflexiva o basada en el conocimiento de la BI, el análisis operativo consiste en monitorear los datos en tiempo real para tomar medidas inmediatas. Por ejemplo, un equipo de una plataforma de comercio electrónico podría necesitar supervisar un panel con métricas de rendimiento del sitio web en tiempo real. Si el sitio web deja de funcionar por algún motivo, ya sea por un aumento en el tráfico de usuarios o por la desconexión de un centro de datos, deben saberlo de inmediato para poder evaluar la situación y volver a poner el sitio en funcionamiento. Y en este caso, su función como ingeniero de datos consistiría en ingerir, transformar y entregar los datos de eventos de los registros de aplicaciones del sitio web para completar el panel de control del equipo de la plataforma. Si bien la inteligencia empresarial y el análisis operativo son prácticas de datos centradas internamente que se han utilizado durante muchas décadas, una tendencia algo más reciente es la analítica integrada externa o orientada al cliente. Lo más probable es que usted mismo haya interactuado con una variedad de aplicaciones de análisis integradas. Por ejemplo, tu banco puede proporcionarte paneles que muestren las tendencias históricas de tus gastos o cómo tus compras se desglosan en diferentes categorías, como alimentos, venta minorista y servicios públicos. O tal vez tenga un termostato inteligente en su hogar que esté conectado a una aplicación móvil. La aplicación puede mostrar la temperatura actual dentro de tu hogar, así como métricas históricas, como la temperatura a lo largo del tiempo. Cuando se trata de análisis integrados, como ingeniero de datos, su trabajo consistiría en proporcionar datos históricos y en tiempo real para usarlos en aplicaciones orientadas al usuario. Con el auge del aprendizaje automático en las últimas décadas, es muy probable que su función como ingeniero de datos implique la entrega de datos para casos de uso del aprendizaje automático. Además, estos cursos tratarán el aprendizaje automático de forma independiente de otros casos de uso de servicio, simplemente porque puede implicar complejidades adicionales que queremos analizar en detalle. Por ejemplo, en un caso práctico de aprendizaje automático, es posible que seas responsable de ofrecer almacenes de datos de características que faciliten el entrenamiento de modelos, y es posible que también necesites entregar datos para inferencias en tiempo real o admitir sistemas de catalogación y metadatos que rastreen el historial y el linaje de los datos. Examinaremos más de cerca todos estos escenarios más adelante en estos cursos. Además del análisis y el aprendizaje automático, otro caso de uso común para servir datos es lo que, al menos hoy en día, se denomina ETL inversa. Con la ETL inversa, tomará los datos transformados, así como los resultados del modelo de análisis y, quizás, de aprendizaje automático, y los devolverá a los sistemas de origen. Por ejemplo, supongamos que ha ingerido datos de un sistema de gestión de relaciones con los clientes o CRM, y esto puede incluir información como nombres, información de contacto, datos de formularios u otra información relevante del cliente, y luego ha transformado los datos al formato adecuado y los ha almacenado en un almacén de datos. Luego, los analistas pueden recuperar los datos para entrenar un modelo de puntuación de clientes potenciales, que es un modelo que intenta determinar qué clientes son los más prometedores para las diversas contrataciones u ofertas de productos. Luego, los resultados del modelo podrían devolverse al almacén de datos y luego volver al CRM como una mejora de los datos del cliente ya almacenados allí. Ahora, solo diré que el nombre ETL inverso para este proceso no es tanto un intento de describir lo que está sucediendo como lo es simplemente por la falta de un nombre mejor para describir este proceso bastante antiguo. En cualquier caso, esta práctica es cada vez más común y, en su trabajo como ingeniero de datos, es probable que se dedique a la ETL inversa, o como se llame en el futuro, como parte de su función. Y con eso, hemos analizado rápidamente todas las fases del ciclo de vida de la ingeniería de datos, incluidos los sistemas de origen, la ingestión, la transformación, el almacenamiento y el servicio. En la siguiente lección, nos centraremos en las corrientes subyacentes del ciclo de vida para abordar todas estas fases. Nos vemos en la próxima lección.

