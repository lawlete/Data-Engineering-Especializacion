En el siguiente laboratorio, utilizará Great Expectations para aplicar pruebas de calidad de datos. Pero antes de continuar, me gustaría ofreceros una visión general de los componentes principales de Great Expectations con un ejemplo de flujo de trabajo. Cuando trabajas con Great Expectations, normalmente comienzas tu flujo de trabajo especificando los datos que deseas probar. A continuación, define las expectativas o las pruebas que desea realizar con los datos y, por último, valida los datos en función de sus expectativas. Para implementar un flujo de trabajo de este tipo, debe interactuar con los componentes principales de Great Expectations, que consisten en el contexto de los datos, las fuentes de datos, las expectativas y los puntos de control. Estos componentes se utilizan para acceder, almacenar y gestionar los objetos y procesos necesarios en el flujo de trabajo. Para iniciar el flujo de trabajo, primero debe crear una instancia de un objeto de contexto de datos. Un contexto de datos sirve como punto de entrada para la API Great Expectations, que consta de clases y métodos que permiten crear objetos para conectarse a las fuentes de datos, crear expectativas y validar los datos. Con el contexto de datos, puede configurar y acceder a las propiedades, como los objetos, así como a los metadatos de su proyecto Great Expectations. Después de crear una instancia del objeto de contexto de datos, debe declarar el objeto de la fuente de datos, lo que indica las grandes expectativas de dónde obtener los datos que desea validar. La fuente de datos puede ser una base de datos SQL, un sistema de archivos local, un bucket de S3 o incluso un marco de datos de pandas. Después de conectarse a la fuente de datos, debe indicar a Great Expectations en qué parte de los datos debe centrarse. Para ello, declare sus activos de datos desde la fuente de datos. Un activo de datos es una colección de registros dentro de una fuente de datos. Puede ser una tabla de una base de datos SQL o un archivo de un sistema de archivos. También puede ser un recurso de consulta que une datos de más de una tabla, o puede ser una colección de archivos que coincidan con un patrón de expresiones regulares en particular. Puede dividir aún más los datos de su activo en lotes. Por ejemplo, si su activo de datos representa los registros que corresponden a las ventas de un año determinado en una tabla, puede dividir los registros en lotes mensuales y validar cada lote. O puede particionar sus datos con respecto a los identificadores de la tienda. También puede trabajar con todos los registros de su activo de datos como un solo lote para recuperar los lotes de su activo de datos. Ya sea un lote o varios lotes, debe crear un objeto de solicitud por lotes a partir de su activo. Las solicitudes por lotes son la forma principal de recuperar datos del activo de datos y es lo que debe proporcionar para el resto de los componentes de Great Expectations. A continuación, debe definir sus expectativas. Una expectativa es una declaración que puedes usar para verificar si tus datos cumplen una condición determinada. Por ejemplo, puede definir una expectativa para comprobar si una columna no contiene valores nulos. Puede definir su propia expectativa o usar una de las declaraciones disponibles en la galería de expectativas. Por ejemplo, esperar que el mínimo de la columna esté entre, esperar que los valores de la columna sean únicos y esperar que los valores de la columna sean nulos son ejemplos de pruebas que puedes usar directamente. Verás cómo puedes llamarlos en el ejemplo de flujo de trabajo en el que trabajaremos. También puede definir más de una expectativa para su activo de datos y recopilarlas en un objeto de conjunto de expectativas. Ahora, para validar sus datos, debe crear un objeto validador que espere una solicitud por lotes y su correspondiente conjunto de expectativas. Puede validar manualmente los datos interactuando directamente con el validador, o puede simplificar el proceso de validación mediante un objeto de punto de control. Un punto de control toma una solicitud por lotes y un conjunto de expectativas y los proporciona automáticamente a un validador que genera los resultados de la validación. A lo largo de este proceso, se generarán metadatos sobre su proyecto y, con grandes expectativas, los guardarán en algunos almacenes de back-end. Great Expectations es compatible con diferentes tipos de tiendas. Las tiendas más comunes son Expectation Store, donde puede encontrar sus suites de expectativas. El almacén de validación, donde puede encontrar información sobre los objetos generados al validar los datos comparándolos con el conjunto de expectativas. La tienda Checkpoint, donde puede encontrar las configuraciones de sus puntos de control. Y una tienda de documentos de datos, donde puede encontrar informes sobre expectativas, puntos de control y resultados de validación. Puede acceder a estos almacenes y a sus ajustes a través del objeto de contexto de datos. Estos son los pasos de un flujo de trabajo típico de Great Expectations. En el siguiente vídeo, aplicaremos estos pasos en un conjunto de datos de ejemplo.

En el vídeo anterior, ha aprendido acerca de los componentes básicos de las expectativas de calificación y cómo es un flujo de trabajo de validación típico. Apliquemos ahora estos pasos en un conjunto de datos de ejemplo, que es la Base de datos de alquiler de DVD, que ha visto en uno de los laboratorios de la primera semana de este curso. Sólo nos centraremos en comprobar las columnas de la tabla de pagos. En concreto, comprobaremos si la columna id de pago contiene ids únicos, la columna id de cliente no contiene valores nulos, y todos los valores de la columna importe son no negativos. Ya he configurado una base de datos postgresSQL localmente en mi máquina y cargado los datos en la base de datos. En el terminal haré pip install grandes expectativas. Después, para iniciar el proyecto grandes expectativas, escribiré great expectations init. Este comando inicializará el objeto de contexto de datos, configurar la estructura de la carpeta de su proyecto como se muestra aquí, y crear sus tiendas backend como los puntos de control, las expectativas, datos docs, y las tiendas de validación como directorios locales. Escribiré Y para proceder, siempre se puede cambiar la ubicación de sus tiendas backend. Así, por ejemplo, en el laboratorio va a configurar sus tiendas como s tres cubos. En este video ill mantener estos como directorios locales. Ahora, para interactuar con los componentes de grandes expectativas, voy a lanzar un Jupyter notebook en el mismo directorio raíz y crear este archivo notebook, ejemplo. Aquí en el archivo notebook, primero importaré el paquete de grandes expectativas y luego llamaré al método get context, para obtener el objeto context del proyecto. Usando este objeto, puedes conectarte a la fuente de datos, definir tus expectativas, crear un validador, y luego ejecutar tus puntos de control. Así que vamos a utilizar este contexto para crear primero el objeto fuente de datos. Create expectations proporciona diferentes métodos que te permiten conectarte a tus diferentes fuentes de datos. Para conectarme a mi base de datos SQL local, llamaré al método context sources add sql, y luego elegiré my datasource como nombre para la fuente de datos. Este método también espera una cadena de conexión que incluye la información necesaria para conectarse a la base de datos, como el nombre de usuario, la contraseña, el nombre de host, el número de puerto y el nombre de la base de datos. Este es el formato de la cadena que puedes usar para conectarte a una base de datos postgresql . Usando este formato, crearé la cadena de conexión a mi base de datos usando la información de mi base de datos local. A continuación, desde el origen de datos, crearé el activo de datos llamando al método add tableasset. Como sólo nos estamos centrando en la tabla de pagos, elegiré el nombre para el activo como payment tb y luego especificaré el nombre de la tabla dentro de la base de datos origen, que es payment. En este caso. Ahora, si quieres crear lotes en tu activo, grandes expectativas proporciona un conjunto de métodos que te permite dividir tu activo de datos basado en la fecha o un valor de columna. Así que por ejemplo, llamaré aquí al método add splitter datetime part en el activo que acabo de crear, y luego indicaré el nombre de la columna que contiene la fecha, que es payment date, y especificaré month para el segundo argumento datetime parts. Y por último, crearé el objeto de solicitud de lote llamando al método build batch request sobre el objeto asset. Antes de continuar con el flujo de trabajo, echemos un vistazo rápido a los lotes. Usando el objeto asset, llamaré al método get batch list from batch requests y pasaré el objeto de solicitud de lote que acabo de crear y luego iteraré sobre los lotes para comprobar la especificación de cada lote. Puedes ver que los datos contienen cuatro lotes donde cada lote corresponde a un mes. Ahora que tenemos el objeto batch request creado, vamos a definir las expectativas. Lo haré de forma interactiva trabajando directamente con un validador. Primero, crearé el conjunto de expectativas que contendrá todas las expectativas que definirá. Sobre el objeto context llamaré al método add o update expectation suite y elegiré el nombre mysuite. Ahora, para crear el validador, utilizaré el objeto de contexto para llamar al método get validator y introduciré el objeto de solicitud de lote y el nombre del conjunto de expectativas. Ahora, utilizando el validador, puedes llamar a cualquiera de los métodos de expectativas desde la galería de expectativas. Así que aquí llamaré a expect column values to be unique para comprobar la unicidad de los valores dentro de la columna payment id. Los resultados que se muestran aquí, corresponden al último lote. Sin embargo, todos los lotes se probaron y, puesto que llegamos al último lote, significa que la prueba se ejecutó correctamente en todos los demás lotes. Ahora definiré dos expectativas más. Esperar que los valores de columna no sean nulos en la columna id de cliente para comprobar que la columna no contiene ningún valor nulo, y Esperar que el valor mínimo de columna esté entre en la columna importe para comprobar que todos los valores de la columna son nulos negativos. Puede ver que ambas pruebas se ejecutan correctamente. Ahora estas tres expectativas que he creado interactivamente mientras trabajaba con el validador sólo están disponibles para esta sesión. Para poder utilizar estas expectativas en otras sesiones, es necesario guardarlas. Usando el validador, llamaré al método guardar conjunto de expectativas y especificaré para grandes expectativas que no descarte las expectativas fallidas, este método guarda el conjunto de expectativas, mi conjunto que contiene las tres expectativas en el almacén de expectativas. Ahora, vamos a automatizar el proceso de la validación utilizando el objeto checkpoint. Para crear el objeto checkpoint, llamaré al método add o update checkpoint en el objeto context y le asignaré el nombre mycheckpoint. Este método espera validaciones como segundo argumento que consiste en una lista de pares de un lote de datos y su correspondiente conjunto de expectativas de para especificar estas validaciones he iterado a través de los lotes y para cada lote he extraído la petición del lote y he usado el nombre del conjunto de expectativas. Ahora ejecutaré el punto de comprobación llamando al método run, la prueba de los cuatro lotes superada. Para obtener información más detallada sobre cada resultado, puedes consultar los documentos de datos llamando al método build data docs utilizando el objeto context. Este método devuelve un enlace que abriré para consultar los documentos de datos. Aquí puedes encontrar los resultados de las validaciones realizadas en cada lote. Puedes ver que todas las pruebas fueron exitosas. Si haces clic en cualquier fila, puedes encontrar estadísticas sobre las expectativas evaluadas, así como las expectativas exitosas y no exitosas. También puedes encontrar las expectativas realizadas en cada columna y el resultado correspondiente. Así que vamos a hacer clic en mostrar más información. Aquí encontrarás algunos metadatos sobre la ejecución del punto de control y los lotes utilizados. Ahora, volvamos a la página de inicio y hagamos clic en la pestaña suites de expectativas. Aquí encontrarás información sobre la suite de expectativas, mi suite. Y ahí lo tienes. Ahora ya sabes cómo interactuar con los componentes principales de las expectativas de grado. Ahora, es tu turno de practicar el uso de grandes expectativas y validar algunos datos en el laboratorio.

[Opcional] Conversación y notas adicionales
Estado: Traducido automáticamente del Inglés
Traducido automáticamente del Inglés
Información:
Este elemento incluye contenido que aún no se tradujo a tu idioma preferido.
Principales conclusiones de la conversación con Barr Moses

Los problemas con los datos son inevitables y pueden producirse en cualquier fase del proceso de datos. Cuanto antes se detecten, menos daño causarán a la organización. Para detectar problemas con los datos, primero hay que elegir indicadores que evalúen la calidad de los datos, de forma similar a cómo los equipos de software controlan los indicadores que evalúan la salud de la infraestructura de su software.

En su libro(Data Quality Fundamentals

), Barr Moses sugiere empezar con las siguientes preguntas:

    ¿Están actualizados los datos?

    ¿Están completos los datos?

    ¿Están los campos dentro de los rangos esperados?

    ¿Es el índice de nulos mayor o menor de lo que debería?

    ¿Ha cambiado el esquema?

Formuló estas preguntas en 5 pilares para la observabilidad de los datos, cuyo objetivo es describir completamente el estado de los datos. 
Los 5 pilares de Barr Moses

    Distribución/ Calidad interna: El pilar de la calidad se refiere a las características internas de los datos, y comprueba métricas como el porcentaje de elementos NULOS, el porcentaje de elementos únicos, las estadísticas de resumen y si tus datos están dentro de lo esperado. Le ayuda a asegurarse de que sus datos son fiables en función de sus expectativas de datos.

    Frescura: La frescura de los datos se refiere a lo "frescos" o "actualizados" que están los datos dentro del activo final (tabla, informe BI), es decir, cuándo se actualizaron los datos por última vez y con qué frecuencia se actualizan. Los datos obsoletos suponen una pérdida de tiempo y dinero.

    Volumen: Volumen de datos se refiere a comprobar la cantidad de datos ingeridos y buscar picos o caídas inesperadas. Las caídas repentinas en el volumen de datos pueden indicar problemas como pérdida de datos o interrupciones del sistema, y los aumentos repentinos pueden indicar aumentos inesperados en el uso.

    Linaje: Según Barr

    , "cuando los datos se rompen, la primera pregunta es siempre "¿dónde?" El linaje de datos le ayuda a trazar el viaje de los datos desde su origen hasta su destino, visualizando cómo se transformaron los datos y dónde se almacenaron. De este modo, se puede identificar el origen de errores o anomalías.  

    Esquema: El esquema de datos se refiere a la supervisión de los cambios en la estructura o los tipos de datos. Este pilar ayuda a evitar fallos en la canalización de datos.

Recursos adicionales

Si desea obtener más información sobre la observabilidad de los datos, puede consultar los siguientes recursos adicionales.

    Fundamentos de la calidad de datos 

, por Barr Moses, Lior Gavish, Molly Vorweck [libro]

The rise of data downtime

, por Barr Moses [artículo]

¿Qué es la observabilidad de los datos?
 por Andy Petrella [libro]
