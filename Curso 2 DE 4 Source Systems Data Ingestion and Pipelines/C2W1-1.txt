Bienvenido al segundo curso de la especializaci칩n en ingenier칤a de datos. En el primer curso, obtendr치 una visi칩n general de alto nivel del campo de la ingenier칤a de datos, los principios de una buena arquitectura de datos y c칩mo traducir las necesidades de las partes interesadas en requisitos y herramientas para sus sistemas de datos. En este curso, aprender치 m치s sobre la ingesti칩n de datos de los sistemas de origen, as칤 como sobre DataOps y la orquestaci칩n de la canalizaci칩n de datos de extremo a extremo. Estoy aqu칤 nuevamente con su instructor, Joe Reis, quien tambi칠n es coautor del superventas Fundamentals of Data Engineering. Joe, 쯣odemos ver un poco sobre lo que ver치n los alumnos en este curso? Claro que s칤, Andrew. Este curso, como ha dicho, incluye un enfoque en las dos primeras etapas del ciclo de vida de la ingenier칤a de datos, que son la generaci칩n y los sistemas fuente de datos y la ingesti칩n de datos de esos sistemas fuente. Empezaremos por analizar los diferentes tipos de sistemas fuente, tal vez cosas como bases de datos o sistemas de almacenamiento y transmisi칩n de objetos. Analizaremos en detalle c칩mo interactuar치 con los sistemas fuente en su trabajo como ingeniero de datos. Despu칠s de eso, analizaremos la ingesta de datos de los sistemas de origen, as칤 como los aspectos de DataOps y orquestaci칩n de la creaci칩n de canalizaciones de datos. Eso suena genial. Para muchos sistemas de IA, la ingenier칤a de datos o la ingesta de datos representan aproximadamente el 80% del trabajo, y luego el modelado del aprendizaje autom치tico representa quiz치s el 20% del trabajo. Sin embargo, la atenci칩n de las personas sobre estos dos temas suele cambiar, ya que el 80% de la atenci칩n se centra en el modelado de la IA y no se presta suficiente atenci칩n , ni en las mejores pr치cticas, y, francamente, tambi칠n en la ingesti칩n de datos. De hecho, en algunos de mis trabajos anteriores, cuando trabajaba en una gran empresa de tecnolog칤a, era responsable del almac칠n de datos de los usuarios de la empresa, por lo que cada dato que afectaba a un usuario individual deb칤a entrar en mi almac칠n de datos, lo que creaba mucho valor para la empresa. Pero ese trabajo intelectual para dise침ar la base de datos, el esquema de la base de datos, el sistema de ingesta, los datos para mantenerla, result칩 ser una tarea bastante ingente. Es una empresa enorme. Siempre he descubierto que cuando hablamos de ingerir datos de los sistemas fuente, esto lo es todo. Si no puede obtener los datos, no hay mucho m치s que pueda hacer con ellos. Esto deber칤a parecer bastante simple, pero como usted se침ala, parece que, muchas veces, se ignora la ingesti칩n o se centra en otras cosas. As칤 que esto es algo fundamental que debes corregir. Si no puede obtener los datos, realmente no puede hacer nada m치s. En esta parte del curso, sin duda, hablaremos sobre la comprensi칩n de los sistemas de origen de los que va a obtener sus datos y las diferentes formas de ingerirlos. Adem치s de las diferentes formas de organizar estos flujos de trabajo de canalizaci칩n de datos y supervisarlos para garantizar que se preserva la calidad de los datos, as칤 como la ingesti칩n, el rendimiento y otras caracter칤sticas, etc., son muy importantes para su trabajo como ingeniero de datos. De hecho, creo que esto es v치lido para muchos flujos de trabajo de datos diferentes, desde los datos de las tablas de estructura hasta los datos estructurados, como textos e im치genes, a medida que la palabra procesa m치s datos estructurados. Esto parece haber permanecido igual. De hecho, incluso cuando hablo con mis amigos que entrenan a los grandes modelos ling칲칤sticos y cuando se trata de liderar equipos de IA, gran parte del tiempo, no todo, pero s칤 mucho tiempo, lo dedico a pensar en los datos. Tambi칠n hay algo relacionado con el entrenamiento de modelos, pero la ingesta de datos ocupa mucho tiempo para todas estas cargas de trabajo de IA. Es muy interesante. Supongo que lo que ven en t칠rminos de las complejidades de la ingesta de datos, porque me imagino que eso funciona a una escala enorme. De hecho, hay muchos datos de Internet. Cosas como Common Crawl contienen muchos datos. Pero teniendo en cuenta los datos, 쯖칩mo se ingieren, se procesan y se filtran para que sean de alta calidad? Adem치s, si tiene lagunas en los datos, si observa que su modelo no tiene 칠xito en estos temas, 쯖칩mo puede averiguar en qu칠 lugares no le va tan bien y en qu칠 parte de la Tierra va a obtener datos, si es que existen para llenar esos vac칤os? Por lo tanto, estas son muchas de las cosas intelectualmente desafiantes por las que la gente que se entrena sobre el terreno, incluso algunos de los principales OM, MM, grandes modelos multimodales y otros grandes modelos b치sicos, dedican tiempo a preocuparse. Eso es fascinante. Una de las cosas de las que hablamos en este curso y que aprender치s es la ingesti칩n de datos de varios tipos de sistemas de origen. Obviamente, vamos a hablar de la ingesta de datos tabulares, pero hoy en d칤a ese es un subconjunto muy peque침o del universo total de datos. Cuando hablamos de conjuntos de datos no estructurados, desde texto hasta im치genes y v칤deos, este universo se est치 convirtiendo cada vez m치s en un universo mucho m치s grande. Yo dir칤a que tradicionalmente hemos utilizado o pensado en el mundo de los datos. Una de las cosas que trataremos en este curso, una vez m치s, no es solo los conjuntos de datos estructurados de las bases de datos, sino que tambi칠n comenzaremos a trabajar con texto , datos de im치genes, etc. Esto lo ayudar치 a prepararse como ingeniero de datos, no solo para las cargas de trabajo actuales, tal vez si trabaja en un almac칠n de datos, sino tambi칠n para las cargas de trabajo del futuro. La mayor parte del valor de los datos probablemente haya sido informaci칩n estructurada hasta este momento. Sin embargo, a medida que crezca nuestra capacidad para procesar datos no estructurados, veremos si eso cambia. Quiz치 ya est칠 cambiando. El volumen de datos no estructurados en el mundo es mucho mayor que el volumen de datos estructurados en el mundo. Creo que esto supondr칤a a칰n m치s desaf칤os e incluso m치s puestos de trabajo para los ingenieros de datos. Exactamente. Esperamos que esta sea una introducci칩n muy interesante al ciclo de vida de la ingenier칤a de datos. Una vez m치s, la ingesti칩n de los sistemas de origen , la organizaci칩n de estas cargas de trabajo y la supervisi칩n de estas cargas de trabajo son fundamentales para su trabajo como ingeniero de datos. Una vez m치s, como se침al칩 Andrew, solo se volver치 m치s interesante, m치s emocionante y mucho m치s grande. Muchas cosas interesantes. Pasemos al siguiente v칤deo para profundizar en todos estos temas.

Programa
Estado: Traducido autom치ticamente del Ingl칠s
Traducido autom치ticamente del Ingl칠s
Informaci칩n:
Este elemento incluye contenido que a칰n no se tradujo a tu idioma preferido.
쮻e qu칠 trata este programa?

Este programa fue dise침ado por Joe Reis en colaboraci칩n con DeepLearning.IA y AWS para cubrir los fundamentos de la ingenier칤a de datos, tanto en t칠rminos de la teor칤a subyacente y marcos para pensar como un ingeniero de datos, as칤 como habilidades pr치cticas para la construcci칩n de soluciones de ingenier칤a de datos en la nube.
쮸 qui칠n va dirigido este programa?

Este programa est치 dise침ado para cualquier persona interesada en seguir una carrera en o adyacente a la ingenier칤a de datos. Puede que seas estudiante o que ya trabajes profesionalmente en un campo relacionado con los datos. En cualquiera de los casos, le interesa adquirir habilidades y conocimientos de ingenier칤a de datos para respaldar sus objetivos profesionales. Incluso si ya est치 trabajando como ingeniero de datos, encontrar치 valor en la combinaci칩n de conocimientos te칩ricos y aplicaciones t칠cnicas que se presenta aqu칤. 
쯈u칠 conocimientos previos necesito para realizar este curso?

    Se requierenconocimientos intermedios de programaci칩n en Python, incluida la familiaridad con la sintaxis, las estructuras de datos, las funciones y las clases de Python. Tambi칠n puede ser 칰til estar familiarizado con los dataframes de Pandas, aunque no es obligatorio. Para aprender los conceptos b치sicos de Pandas, recomendamos los tutoriales de Pandas de la Escuela W3

 o los tutoriales de Pandas de Kaggle

. 

Tambi칠n puede ser 칰tilestar familiarizado con SQL , pero no es necesario. No dudes en consultar el curso SQLBolt Tutorials

 si quieres aprender los fundamentos de SQL.

Lafamiliaridad b치sica con los fundamentos t칠cnicos de la nube de AWS ser치 칰til pero no necesaria. Para aprender los fundamentos de AWS recomendamos los cursos AWS Cloud Practitioner Essentials
 y AWS Cloud Technical Essentials

    .

쯈u칠 tiene de especial este programa?

    Este programa leense침a a pensar como un ingeniero de datos
    Este programa le ense침ar치 a pensar como un ingeniero de datos a la hora de dise침ar, crear y mantener sistemas que toman datos sin procesar, los convierten en algo 칰til y los ponen a disposici칩n de las partes interesadas. No se trata s칩lo de herramientas y tecnolog칤as En primer lugar, aprender치 a recopilar las necesidades de las partes interesadas y a comprender los problemas empresariales que intentan resolver con los datos. A continuaci칩n, traducir치 esas necesidades en requisitos del sistema y elegir치 las herramientas y tecnolog칤as adecuadas para las soluciones que pretende crear. Al final de este programa, dispondr치 de un s칩lido marco mental que podr치 aplicar a cualquier proyecto de ingenier칤a de datos.

    Pr치ctica
    Tendr치s muchas oportunidades de practicar la aplicaci칩n del marco mental para pensar como un ingeniero de datos a trav칠s de actividades pr치cticas. Participar치 en conversaciones simuladas con las partes interesadas y se le pedir치 que re칰na requisitos para sus sistemas de datos. Dise침ar치 e implementar치 canalizaciones de datos de streaming y por lotes de extremo a extremo en la nube de AWS, solucionar치 problemas comunes a los que se enfrentan muchos nuevos ingenieros de datos, utilizar치 herramientas populares de c칩digo abierto para orquestar y monitorizar sus canalizaciones de datos, crear치 arquitecturas de almacenamiento de lago de datos y data lakehouse, consultar치, modelar치 y transformar치 sus datos utilizando varios marcos de procesamiento, y servir치 datos a las partes interesadas aguas abajo para casos de uso de an치lisis empresarial y aprendizaje autom치tico. Este programa adopta un enfoque justo a tiempo para presentarle las herramientas y tecnolog칤as que necesitar치 para cada ejercicio, y se le guiar치 a trav칠s de cada paso de los laboratorios con instrucciones detalladas y gu칤as en v칤deo.

Libro de texto y lecturas

    Fundamentos de la ingenier칤a de datos

    A lo largo del curso se proporcionar치 material de lectura complementario

Esquema del programa

Este programa est치 estructurado en 4 cursos.

Curso 1 - Introducci칩n a la ingenier칤a de datos

Este curso consta de 4 semanas de contenido y cubre estos objetivos principales de aprendizaje:

    Identificar los principales colaboradores y partes interesadas para los ingenieros de datos

    Articular un marco mental para construir soluciones de ingenier칤a de datos

    Identificar algunas de las consideraciones necesarias para la recopilaci칩n de requisitos al inicio de un nuevo proyecto

    Describir la estructura del ciclo de vida de la ingenier칤a de datos y sus corrientes subyacentes, y c칩mo pensar en los problemas de ingenier칤a de datos a trav칠s de esta lente

    Identificar algunas de las tecnolog칤as clave que pueden emplearse en las distintas fases del ciclo de vida de la ingenier칤a de datos

    Evaluar tecnolog칤as y herramientas en el contexto de los requisitos y una buena arquitectura de datos

    Dise침ar una arquitectura de datos en AWS basada en los requisitos de las partes interesadas

    Implementar una canalizaci칩n por lotes y de streaming en AWS para respaldar un sistema de recomendaci칩n de productos

Curso 2 - Sistemas de origen, ingesti칩n de datos y canalizaciones

Este curso consta de 4 semanas de contenido y cubre estos objetivos de aprendizaje principales:

    Identificar diferentes formatos de datos y determinar los sistemas de origen apropiados para generar cada tipo de datos

    Explicar a alto nivel c칩mo se generan, almacenan y recuperan los datos en varios sistemas fuente, incluyendo bases de datos relacionales, bases de datos NoSQL, almacenamiento de objetos y sistemas de streaming

    Explicar los fundamentos de las redes en la nube

    Solucionar errores de conexi칩n a bases de datos

    Explicar la diferencia entre las ingestas por lotes y por flujo e identificar casos de uso para cada patr칩n

    Diferenciar entre los dos patrones de ingesta por lotes: Extracci칩n-Transformaci칩n-Carga (ETL) y Extracci칩n-Carga-Transformaci칩n (ELT)

    Crear un script para ingestar datos desde una API REST

    Describir los componentes b치sicos de una plataforma de flujo de eventos

    Interactuar con una plataforma de transmisi칩n de eventos como sistema de origen y como herramienta de ingesti칩n

    Utilizar Terraform para aprovisionar recursos de AWS para su canalizaci칩n de datos

    Identificar herramientas para monitorizar sus sistemas de datos y la calidad de los datos

    Identificar y monitorizar m칠tricas de calidad de datos relevantes

    Explicar c칩mo se puede aplicar la orquestaci칩n a un canal de datos y enumerar sus beneficios

    Construir canalizaciones de datos con DAGs en Airflow utilizando funciones como Taskflow API, operadores, variables XCom, etc.

Curso 3 - Almacenamiento de datos y consultas

Este curso consta de 3 semanas de contenido y cubre estos objetivos de aprendizaje principales:

    Explicar c칩mo se almacenan f칤sicamente los datos en el disco y en la memoria

    Comparar c칩mo se almacenan y consultan los datos en sistemas de almacenamiento de objetos, bloques y archivos

    Explicar c칩mo se almacenan los datos en bases de datos orientadas a filas frente a bases de datos orientadas a columnas

    Explicar c칩mo almacenan y recuperan datos las bases de datos gr치ficas y vectoriales

    Explicar las caracter칤sticas arquitect칩nicas clave de los almacenes de datos, los lagos de datos y los data lakehouses

    Implementar un lago de datos con AWS Glue

    Implementar un lago de datos con una arquitectura tipo medall칩n utilizando Lake Formation e Iceberg

    Explicar las etapas de la vida de una consulta

    Implementar consultas SQL avanzadas

    Explicar el papel de un 칤ndice y su impacto en el rendimiento de la consulta

    Resumir los enfoques para procesar consultas agregadas y join

    Comparar los tiempos de ejecuci칩n de consultas agregadas entre almacenamiento en filas y en columnas

    Enumerar algunas estrategias para mejorar el rendimiento de las consultas

    Agregaci칩n y uni칩n de flujos de datos

Curso 4 - Modelamiento de datos, Transformaci칩n y Servicio de Datos

Este curso consta de 4 semanas de contenido y cubre estos objetivos principales de aprendizaje:

    Definir el Modelamiento de datos y su rol en reflejar la l칩gica del negocio

    Aplicar las etapas de normalizaci칩n a una tabla desnormalizada

    Describir las tablas de hechos y dimensiones de un esquema en estrella y transformar datos en tercera forma normal a un esquema en estrella

    Describir los enfoques de modelado de almacenes de datos como Inmon, Kimball, Data Vault y One Big Table

    Utilizar la Ingenier칤a de caracter칤sticas para convertir un conjunto de datos en una forma tabular esperada por los algoritmos cl치sicos de Aprendizaje autom치tico

    Preprocesar y vectorizar datos textuales

    Enumerar t칠cnicas para procesar y aumentar los datos de im치genes

    Comparar un marco de procesamiento en memoria como Spark y un marco de procesamiento basado en disco como Hadoop

    Describir las consideraciones t칠cnicas para elegir un marco de procesamiento distribuido, como Spark, frente a un marco no distribuido como Pandas dataframes

    Describir las consideraciones t칠cnicas para utilizar Spark SQL frente a Spark DataFrames al transformar datos utilizando PySpark

    Describir c칩mo funciona la transformaci칩n de flujo con un motor de procesamiento casi en tiempo real como Spark Structured Streaming

    Identificar diferentes formas de servir datos para casos de uso de anal칤tica y aprendizaje autom치tico

    Describir el prop칩sito de una capa sem치ntica que se asienta sobre el modelo de datos

    Creaci칩n de vistas y vistas materializadas

    Describir los beneficios e inconvenientes de servir datos utilizando vistas y vistas materializadas

Actividades de aprendizaje utilizadas en este programa

    V칤deos de conferencias: Una colecci칩n de videos cortos que cubren la teor칤a subyacente, as칤 como demostraciones de herramientas y tecnolog칤as importantes que necesita para cada semana. Tambi칠n hay v칤deos "Lab Walkthrough" que le dan una visi칩n general de alto nivel de los laboratorios antes de sumergirse en ellos. Algunos de los v칤deos est치n etiquetados como "[Opcional]", y est치n dise침ados para complementar su experiencia de aprendizaje, pero no ser치 evaluado en este contenido. Algunos de estos v칤deos opcionales est치n protagonizados por expertos del sector y su objetivo es proporcionarle informaci칩n pr치ctica de veteranos en el campo de opciones.

    Laboratorios: Ejercicios pr치cticos que le permitir치n aplicar lo aprendido en los v칤deos de las clases. Est치n dise침ados para ayudarle a desarrollar habilidades para determinadas tecnolog칤as de c칩digo abierto o AWS que se utilizan habitualmente al crear soluciones de ingenier칤a de datos. Hay dos tipos de laboratorios:

        Tareas de programaci칩n calificadas: Estas tareas de laboratorio cubren conceptos cr칤ticos para esa semana, y por lo general representan un mayor porcentaje de su calificaci칩n.

        Laboratorios de pr치ctica: Estos laboratorios no se califican. Los conceptos cubiertos en estos laboratorios siguen siendo importantes. Sin embargo, para reducir la presi칩n de tener que sobresalir en todos los laboratorios, hemos decidido designar algunos de ellos como "pr치cticas". De esta manera, usted puede centrarse en el aprendizaje de los laboratorios en lugar de simplemente completarlos para obtener una calificaci칩n. Te animamos a que pruebes todos los laboratorios, tanto si se califican como si son pr치cticos

    Cuestionarios: Una colecci칩n de preguntas para ayudarle a reforzar su aprendizaje sobre los conceptos cubiertos en cada semana. Encontrar치 un cuestionario calificado al final de cada semana, y la calificaci칩n que obtenga en esos cuestionarios contribuir치 a su calificaci칩n general para cada curso. Ocasionalmente encontrar치 cuestionarios de pr치ctica que contienen preguntas de reflexi칩n o breves cuestionarios calificados que contienen preguntas para comprobar su comprensi칩n a lo largo de la semana. Despu칠s de completar cada cuestionario, aseg칰rese de leer atentamente los comentarios.

    Lectura: Contenido presentado en formato textual para que pueda consultar la informaci칩n m치s adelante con mayor facilidad. Algunos de estos elementos de lectura incluir치n enlaces adicionales para que pueda obtener m치s informaci칩n sobre el tema. A menos que se especifique lo contrario, no es necesario que revise los materiales de estos enlaces externos para tener 칠xito en este programa. Algunas de estas lecturas est치n etiquetadas como "[Opcional]" y cubren material secundario que no es cr칤tico para el programa. Usted puede revisar estas lecturas si est치 interesado, pero no ser치 evaluado en este contenido.

쮺칩mo se califican las evaluaciones?

Se requiere una calificaci칩n de 80% o m치s para aprobar todos los elementos de evaluaci칩n (cuestionarios, laboratorios de pr치ctica y tareas de programaci칩n calificadas). Por favor, consulte la pesta침a"Calificaciones" de la p치gina principal del curso para ver sus calificaciones para cada evaluaci칩n.
Obtener y dar ayuda

Preguntas relacionadas con el contenido del curso: Se le anima a unirse a la comunidad DeepLearning.IA donde se puede llegar a los mentores del curso y compa침eros de clase para obtener ayuda con cualquier problema relacionado con el contenido del curso. 춰Puedes hacer clic 游댕 este enlace

 para crear tu cuenta gratuita y conectarte con la comunidad global de IA!

Preguntas relacionadas con la plataforma Coursera: Puedes consultar el Centro de ayuda al alumno
 para encontrar informaci칩n relacionada con problemas t칠cnicos espec칤ficos. Por ejemplo, los problemas t칠cnicos incluir칤an mensajes de error, dificultad para enviar tareas o problemas con la reproducci칩n de v칤deos.

Bienvenido a la primera semana de este curso sobre sistemas de origen, ingesti칩n y canalizaciones de datos. Esta semana, vamos a empezar por analizar los diferentes tipos de sistemas fuente y c칩mo puedes interactuar con estos sistemas. Como vio en el primer curso de la especializaci칩n, la generaci칩n de datos en los sistemas fuente es la primera etapa del ciclo de vida de la ingenier칤a de datos. Y como ingeniero de datos, normalmente no es responsable de generar estos datos usted mismo ni de mantener estos sistemas de origen. Sin embargo, la ingesti칩n desde los sistemas fuente es donde comenzar치n todas sus canalizaciones de datos. Por lo tanto, es importante que comprenda c칩mo se generan estos datos, d칩nde y c칩mo se almacenan. Y algunas de sus caracter칤sticas permiten crear canalizaciones de datos s칩lidas con estos sistemas ascendentes como fuente de datos. Por eso, en esta primera semana de este curso, profundizaremos en algunos de los detalles de algunos sistemas fuente comunes, incluidos los diferentes tipos de bases de datos, almacenamiento de objetos y fuentes de streaming. En los laboratorios, podr치 trabajar con estos sistemas fuente en AWS. Luego, en la segunda semana, nos centraremos en configurar diferentes tipos de ingesti칩n desde los sistemas fuente. Despu칠s de eso, en la semana 3 de este curso, analizaremos las DataOps actuales. Utilizar치 la infraestructura como c칩digo para automatizar algunas de las tareas de canalizaci칩n y utilizar치 varias herramientas para supervisar la calidad de los datos. Y, por 칰ltimo, en la cuarta y 칰ltima semana del curso, nos ocuparemos de la organizaci칩n para coordinar las tareas de sus canalizaciones de datos. Configurar치 gr치ficos ac칤clicos dirigidos, o DAG, mediante el flujo de aire, trabajar치 con la infraestructura como marcos de c칩digo e implementar치 soluciones de monitoreo para sus canalizaciones de datos. As칤 que vamos a cubrir mucho terreno en este curso. Acomp치침eme en el siguiente v칤deo para empezar a analizar m치s de cerca los diferentes tipos de sistemas fuente.

Los sistemas fuente espec칤ficos con los que trabajar치 como ingeniero de datos suelen variar seg칰n el tipo de datos que ingiera de esos sistemas. El tipo de datos m치s com칰n con el que trabajar치 son los datos estructurados, es decir, los datos organizados como tablas de filas y columnas. Lo m치s probable es que hayas trabajado con datos estructurados en el pasado, ya sea en una hoja de c치lculo o en una base de datos relacional, o tal vez incluso hayas usado Python para leer un archivo CSV. Los otros tipos de datos que encontrar치 como ingeniero de datos son los datos semiestructurados y no estructurados. Los datos semiestructurados son datos que no est치n en forma tabular, por lo que no se componen de filas y columnas, pero a칰n tienen cierta estructura. Un formato de datos semiestructurados com칰n con el que te encontrar치s es lo que se conoce como notaci칩n de objetos de JavaScript o JSON. Un archivo JSON contiene una serie de pares clave-valor. En este ejemplo, la primera clave es FirstName con el valor correspondiente Joe. La siguiente clave es LastName con el valor correspondiente Reis. Y con el formato JSON, todos estos pares clave-valor se enumeran entre llaves como este. Y puedo tener m치s pares clave-valor, incluida la informaci칩n que quiera registrar en este formato. Cada valor puede adoptar un tipo de datos diferente, por ejemplo, un n칰mero, una cadena o una matriz. De hecho, el valor de un par clave-valor puede ser incluso otra serie de pares clave-valor. Y como puedes ver en este ejemplo, el valor de direcci칩n tiene una clave: ciudad , c칩digo postal y pa칤s con los valores correspondientes. Esto crea lo que se denomina un formato JSON anidado. Por lo tanto, como puede ver, aunque los datos no se presenten como una tabla, estos datos todav칤a tienen cierta estructura. Los datos no estructurados, por otro lado, no tienen una estructura predefinida. Por ejemplo, el texto, el v칤deo, el audio y las im치genes son ejemplos de datos no estructurados. Sin embargo, observar치 que cosas como el v칤deo, el audio y las im치genes tienen una estructura inherente detr치s de escena, en el sentido de que hay dimensiones de p칤xeles y colores como el rojo, el azul y el verde. A lo largo de este curso, profundizaremos en los datos no estructurados. Cuando se trata de ingerir estos diferentes tipos de datos, me gustar칤a clasificar los sistemas fuente relevantes que puede encontrar en tres tipos generales: bases de datos, archivos y sistemas de transmisi칩n. Si bien estos tres tipos de sistemas fuente no se corresponden necesariamente uno a uno con los tres tipos de datos que acabo de mencionar, se podr칤a decir que de las bases de datos la mayor칤a de las veces se ingieren datos estructurados y semiestructurados. Desde los sistemas de streaming, con frecuencia ingerir치s mensajes semiestructurados en formato de datos. Y los archivos, bueno, los archivos pueden ser cualquier cosa, desde texto hasta im치genes , audio, v칤deo o incluso filas y columnas antiguas normales de datos tabulares. Empecemos por echar un vistazo m치s de cerca a las bases de datos. Las bases de datos almacenan la informaci칩n de forma organizada que permite buscar, recuperar, actualizar y eliminar datos. Esto funciona mediante un patr칩n transaccional conocido como CRUD, que significa crear, leer, actualizar y eliminar. La C es lo primero porque, por supuesto, los datos deben crearse antes de poder leerlos, actualizarlos o eliminarlos. Tiene sentido, 쯨erdad? Por lo general, hay una interfaz de software llamada sistema de administraci칩n de bases de datos, o DBMS, que se encuentra entre el almacenamiento de la base de datos f칤sica y la persona o la aplicaci칩n que interact칰a con la base de datos. El DBMS es lo que le permite acceder y manipular los datos almacenados en la base de datos. Hay dos tipos de bases de datos que analizaremos esta semana. Bases de datos relacionales, que almacenan informaci칩n en tablas con filas y columnas, y bases de datos no relacionales, tambi칠n conocidas como NoSQL o no solo SQL, que almacenan datos no tabulares. Analizaremos m치s de cerca estos dos tipos de bases de datos a finales de esta semana. Adem치s de las bases de datos, el siguiente tipo de sistema fuente m치s com칰n con el que interactuar치 son los archivos. Sin duda, ya tiene mucha experiencia trabajando con archivos de varios tipos. Pueden ser documentos que almacenas en tu computadora, im치genes o videos que grabas con tu tel칠fono, o incluso un archivo CSV que recibes en un correo electr칩nico de un compa침ero de trabajo. Puede parecer extra침o pensar en los archivos antiguos normales como un sistema fuente para la ingenier칤a de datos, pero en esencia, un archivo es solo una secuencia de bytes que representan informaci칩n. Las aplicaciones de todo tipo escriben datos en los archivos, por lo que los archivos son un medio universal de intercambio de datos. Y aunque no lo crea, son uno de los sistemas fuente m치s comunes con los que trabajar치 como ingeniero de datos. Los archivos, al igual que los datos, pueden estar estructurados como una hoja de c치lculo, semiestructurados como un archivo JSON o XML, o desestructurados como un archivo de texto, imagen, v칤deo o audio. Es posible que recibas estos archivos o accedas a ellos desde un sistema de archivos como Google Drive o un sistema de almacenamiento de objetos como Amazon S3, o simplemente como un archivo adjunto a un correo electr칩nico. El tercer tipo de sistema fuente del que es probable que ingieras datos son los sistemas de streaming. Y puede pensar que los sistemas de streaming proporcionan un flujo continuo de datos, grabados como mensajes que contienen informaci칩n sobre eventos. Y esos eventos incluyen algo que ocurri칩 en el mundo o un cambio en el estado de un sistema. En la pr치ctica, es posible que interact칰es con una secuencia de eventos a trav칠s de colas de mensajes u otras plataformas de transmisi칩n. Por ejemplo, un dispositivo de IoT, como un termostato inteligente, puede registrar un evento que contenga la lectura de temperatura m치s reciente y publicar ese evento como un mensaje en una plataforma de transmisi칩n como Kinesis o Kafka. Luego, como ingeniero de datos, puede configurar otro servicio para incorporar este mensaje y enviar una actualizaci칩n a un panel de an치lisis integrado. En este caso, puedes pensar en la plataforma de streaming como un sistema fuente del que est치s extrayendo datos sin procesar. En las 칰ltimas semanas de este curso, ver치 c칩mo estos sistemas de transmisi칩n tambi칠n pueden abarcar todo el ciclo de vida de la ingenier칤a de datos y usarse en las etapas de ingesti칩n y transformaci칩n para procesar datos para varios casos de uso posteriores. De hecho, puede ver lo mismo en todos los tipos de sistemas fuente, ya sea que se trate de bases de datos, archivos o sistemas de transmisi칩n. Pueden ser sistemas de los que est치 ingiriendo datos sin procesar o pueden ser sistemas que incorpore a sus canalizaciones de datos en otra etapa del ciclo de vida. En resumen, como ingeniero de datos, extraer치 datos sin procesar de diferentes sistemas de origen. Estos datos sin procesar pueden estar estructurados, semiestructurados o no estructurados, y los sistemas fuente pueden ser bases de datos, archivos o sistemas de transmisi칩n. En la pr칩xima serie de v칤deos, profundizar칠 un poco m치s en las caracter칤sticas de cada uno de estos diferentes tipos de sistemas fuente. Empezaremos con las bases de datos, despu칠s veremos c칩mo funciona el almacenamiento de objetos como fuente de datos para los archivos y, a continuaci칩n, profundizaremos en las colas de mensajes, los registros y las plataformas de streaming con m치s detalle. Acomp치침eme en el siguiente v칤deo para empezar a echar un vistazo a las bases de datos relacionales.

Como ingeniero de datos, el tipo de sistema fuente m치s com칰n con el que interactuar치 es una base de datos relacional, y esto se debe a que las bases de datos relacionales est치n en todas partes. Muchas aplicaciones web y m칩viles utilizan bases de datos relacionales en el backend, y usted tambi칠n las encontrar치. En muchos sistemas corporativos, como los sistemas de gesti칩n de relaciones con los clientes , recursos humanos y planificaci칩n de recursos empresariales, tambi칠n se suelen utilizar para lo que se denomina procesamiento de transacciones en l칤nea o sistemas OLTP, en los que es necesario ejecutar un gran volumen de transacciones de forma simult치nea, como en el caso de las reservas bancarias o en l칤nea. El nombre base de datos relacional proviene del hecho de que este tipo de base de datos se usa con mayor frecuencia para almacenar datos en diferentes tablas que est치n relacionadas entre s칤 a trav칠s de un conjunto de claves o atributos comunes. Estas tablas suelen organizarse en funci칩n de c칩mo se estructura la informaci칩n en la empresa. Por ejemplo, como ingeniero de datos que trabaja en una empresa de comercio electr칩nico, es posible que est칠 trabajando con una base de datos relacional en la que una tabla captura la informaci칩n de los clientes, otra tabla captura la informaci칩n de los productos y una tercera tabla captura la informaci칩n de los pedidos. Estructurar una base de datos de esta manera reduce la redundancia y facilita la administraci칩n de los datos al no tener la misma informaci칩n duplicada en varias filas o tablas de la base de datos. Para tener una idea de lo que quiero decir con eso, imagine por un momento que, en lugar de varias tablas, cre칩 una tabla grande para almacenar los datos de cada pedido individual de un cliente. En este caso, la tabla puede contener un gran n칰mero de columnas, incluyendo todo lo relacionado con el cliente, como su nombre, direcci칩n, n칰mero de tel칠fono, etc. Y luego tendr칤as toda la informaci칩n sobre el producto que compraron, como la marca, el n칰mero de SKU, la descripci칩n del producto y otros detalles, as칤 como los detalles del pedido, como la fecha y la hora, el importe de la compra y cu치nto pagaron. Por lo tanto, en este escenario, si un cliente hiciera un pedido de tres productos diferentes, esto se registrar칤a como tres filas independientes en tu base de datos y tendr칤as tres filas en la tabla que contienen todos los mismos datos del cliente. O si tres clientes diferentes compraron el mismo producto, entonces tendr칤as tres filas en la base de datos que contienen informaci칩n id칠ntica para ese producto. En resumen, la informaci칩n se duplicar칤a en varias filas de la tabla y, adem치s, podr칤a haber incoherencias con los datos de las distintas filas. Por ejemplo, si un cliente cambiara su direcci칩n, habr칤a una incoherencia entre las filas, a menos que volvieras y actualizaras todas las filas que contienen su direcci칩n anterior, o si cambiaran los detalles de un producto en particular, tendr칤as que volver y actualizar todas las filas que contienen la informaci칩n anterior. Si, en cambio, separas la informaci칩n de los clientes , los productos y los pedidos en varias tablas, una fila de la tabla de clientes representa a un solo cliente y una fila de la tabla de productos contiene informaci칩n sobre un solo producto. Si un cliente cambia su direcci칩n o cambian los detalles de un producto, solo tienes que actualizar la 칰nica fila que contiene la informaci칩n sobre ese cliente o producto. La forma en que una base de datos se organiza en tablas relacionadas como esta se denomina esquema de base de datos. Las bases de datos relacionales representan estas relaciones entre tablas mediante el uso de claves. Una clave principal es una columna especial o un conjunto de columnas que identifican de forma exclusiva cada fila de una tabla. Para la tabla del cliente, la clave principal podr칤a ser esta columna denominada Id. La relaci칩n entre el cliente y el pedido se puede establecer haciendo que la columna Customer_id y la tabla de pedidos hagan referencia a la columna id de la tabla de clientes. En este caso, la columna de identificador de cliente de la tabla de pedidos se denomina clave externa y hace referencia a la columna de clave principal o identificador de la tabla de clientes. M치s all치 de la estructura de filas de una base de datos relacional, cada columna tiene un nombre 칰nico y un tipo de datos espec칤fico. Por ejemplo, en la tabla de clientes puede tener columnas como ID, nombre y apellidos que contienen cadenas, y otra columna llamada edad que contiene un entero. A continuaci칩n, cada nueva fila de una tabla debe seguir la misma estructura de columnas, es decir, la misma secuencia de columnas y tipos de datos. Esto tambi칠n forma parte del esquema de la base de datos. Ahora, en una base de datos con un esquema como este, para registrar informaci칩n sobre un nuevo pedido de un cliente existente, puedes crear un nuevo registro en la tabla de pedidos e indicar el identificador del cliente de la tabla del cliente y el identificador del producto de la tabla de productos y los detalles del pedido, como la fecha, la hora y el pago, etc. Adem치s, si ese cliente cambia su direcci칩n o cambia el n칰mero de SKU del producto que ha pedido, esos cambios solo afectar치n a una fila de la tabla de clientes o productos, y la informaci칩n se mantendr치 coherente. Como puede imaginar, hay muchas maneras diferentes de establecer relaciones entre tablas, y aqu칤 es donde entra en juego el concepto de normalizaci칩n de datos. La normalizaci칩n de datos es un enfoque que se desarroll칩 en la d칠cada de 1970 para minimizar la redundancia y garantizar la integridad de los datos mediante el almacenamiento de datos en tablas de forma l칩gica. Pero ahora creo que vale la pena hacer una pausa para preguntarnos: 쯣or qu칠 preocuparse tanto por la redundancia o la informaci칩n duplicada en primer lugar? Parece l칩gico y ordenado estructurar los datos como lo he estado describiendo. Pero, 쯛ay alg칰n inconveniente? Bueno, resulta que, si bien una estructura de base de datos relacional normalizada proporciona un alto grado de integridad y minimiza la redundancia, en realidad puede resultar lenta a la hora de consultar los datos. Hoy en d칤a, el almacenamiento es relativamente barato y la velocidad suele ser fundamental. La integridad de los datos es fundamental, por supuesto, pero la respuesta a la forma exacta en que se almacenan los datos tabulares podr칤a depender del objetivo para el que se est칠 intentando optimizar. Como ingeniero de datos, es posible que est칠 ingiriendo datos normalizados de un sistema de base de datos relacional, pero seg칰n el caso de uso final que est칠 atendiendo, puede decidir organizar los datos seg칰n un modelo diferente en sus propios sistemas de almacenamiento. Hoy en d칤a, incluso hay algunos casos de uso en los que los ingenieros de datos eligen adoptar el denominado enfoque de una gran tabla u OBT, en el que todos los datos se registran en una sola tabla para un procesamiento m치s r치pido de lo que ser칤a posible si se unieran varias tablas en una base de datos relacional tradicional. Profundizaremos en los detalles del modelado de datos en el Curso 4, especializaci칩n. Cuando se trata de interactuar con la base de datos, utilizar치 un sistema de administraci칩n de bases de datos relacionales (RDBMS). Es una capa de software que se encuentra en la parte superior de una base de datos relacional. Existen muchos RDBM populares, incluidos MySQL, PostgreSQL, Oracle y SQL Server. La mayor칤a de los RDBMS admiten el lenguaje de consulta estructurado, tambi칠n conocido como secuela o SQL para abreviar. Algunas personas dicen SQL, otras dicen SQL. Puedes elegir lo que prefieras. A veces digo ambas cosas. Lo importante que debe saber es que SQL proporciona un conjunto de comandos para realizar diversas operaciones en las bases de datos relacionales. Y como ingeniero de datos, SQL formar치 parte de su trabajo diario. En el siguiente v칤deo, te explicar칠 algunos de los comandos SQL que necesitar치s para el laboratorio. Luego, en el laboratorio, tendr치 la oportunidad de practicar la consulta de datos en una base de datos relacional mediante consultas SQL. Despu칠s de eso, 칰nase a m칤 en el siguiente v칤deo, eche un vistazo a las bases de datos NoSQL.

En el laboratorio, trabajar치 con una base de datos transaccional para una empresa ficticia de alquiler de DVD llamada Rentio. Esta base de datos incluye tablas que contienen informaci칩n sobre las tiendas, el personal, los clientes, el inventario de DVD y las transacciones de alquiler de Rentio. Escribir치s sentencias o consultas SQL en un Jupyter Notebook para recuperar informaci칩n de esta base de datos con el fin de responder a preguntas empresariales. Para consultar los datos, tendr치 que entender el esquema de la base de datos. En otras palabras, tendr치 que saber los nombres de las tablas, las columnas que contienen y c칩mo se relacionan las tablas entre s칤 a trav칠s de claves principales y externas. Esta base de datos est치 normalizada, lo que significa que los datos, como las direcciones de las tiendas, el personal y los clientes, se almacenan en tablas separadas para reducir la redundancia y facilitar la actualizaci칩n de los datos cuando cambian. Del mismo modo, los datos sobre las pel칤culas y las propias transacciones de alquiler tambi칠n se almacenan en tablas separadas. Puede consultar este modelo de relaciones entre entidades que muestra las relaciones y los atributos de las tablas de la base de datos de Rentio. Para explicarte los conceptos b치sicos de SQL, solo me centrar칠 en tres tablas. La tabla de pel칤culas que contiene informaci칩n como el t칤tulo y la duraci칩n de una lista de pel칤culas, la tabla de categor칤as que contiene una lista de categor칤as de pel칤culas y la tabla film_category que muestra los films_id, junto con sus correspondientes category_id de pel칤cula. La sentencia SQL m치s b치sica comienza con una cl치usula SELECT, en la que se especifican los datos que se desean, seguida de una cl치usula FROM, en la que se especifica de qu칠 tabla se desean recuperar estos datos. Por ejemplo, supongamos que quiero explorar los t칤tulos y los a침os de estreno sin tener en cuenta la mesa cinematogr치fica. Puedo escribir SELECT title, release_year FROM film. Una vez que ejecute esta consulta, obtendr칠 una lista de todos los t칤tulos y a침os de lanzamiento. Resulta que hay 1000 pel칤culas en esta mesa de filmaci칩n. Si no quiero ver la lista completa, puedo limitar el n칰mero de resultados devueltos mediante una cl치usula LIMIT. Por ejemplo, si a침ado LIMIT 10 al final de esta consulta, solo obtendr칠 los 10 primeros t칤tulos y los a침os de estreno de la tabla de pel칤culas. Pero, 쯤u칠 sucede si desea recuperar datos de todas las columnas de una tabla? Bueno, puedes enumerar todos los nombres de las columnas en la cl치usula SELECT de esta manera, o puedes usar un atajo y escribir SELECT * FROM film. Esto recuperar치 los datos de todas las filas y columnas de la tabla de pel칤culas. En el pr칩ximo curso, aprender치 c칩mo se ejecutan las canteras entre bastidores. Pero por ahora, ten en cuenta que recuperar todos los datos de todas las columnas puede requerir muchos recursos de procesamiento, especialmente si tu conjunto de datos es muy grande. Recomiendo usar SELECT * 칰nicamente para recuperar todos los datos de una tabla, donde puede filtrar los resultados con alguna condici칩n booleana. Por ejemplo, supongamos que solo te interesa explorar pel칤culas de menos de 60 minutos de duraci칩n. Puede a침adir una cl치usula WHERE despu칠s de la cl치usula FROM para filtrar los resultados en funci칩n de la longitud de la columna. Escribir칠 SELECT * FROM pel칤cula cuya duraci칩n sea inferior a 60. Esto devolver치 una lista de las 96 pel칤culas que tienen menos de una hora de duraci칩n. Tambi칠n puedes ordenar los resultados por cualquier columna que desees. Por ejemplo, puedo a침adir ORDER BY length despu칠s de la cl치usula WHERE para almacenar los resultados en orden ascendente seg칰n la duraci칩n de la pel칤cula. Si quiero ver los resultados en orden descendente por duraci칩n de la pel칤cula, puedo a침adir la palabra clave D-E-S-C o DESC al final de la cl치usula ORDER BY. Si quisiera limitar los resultados a, digamos, 10 registros, puedo agregar un L칈MITE 10 al final de esta consulta. Acabas de ver c칩mo puedes recuperar datos de una sola tabla usando las cl치usulas SELECT, FROM, WHERE, ORDER BY y LIMIT. 쯈u칠 sucede si desea explorar los datos de m치s de una tabla? Puede usar la cl치usula JOIN para combinar registros de dos o m치s tablas en funci칩n de las columnas compartidas entre esas tablas. Por ejemplo, supongamos que quiero obtener una lista de t칤tulos de pel칤culas y su correspondiente categor칤a_pel칤cula para todas las pel칤culas de menos de 60 minutos de duraci칩n. Modifiquemos la consulta anterior, donde seleccion칠 una estrella de una pel칤cula cuya longitud es inferior a 60. Quiero combinar las filas de la tabla de pel칤culas con las filas de la tabla film_category en funci칩n de los identificadores de pel칤culas coincidentes. Al final de la cl치usula FROM, escribir칠 JOIN film_category ON film.film_id = film_category.film_id. De esta forma, los resultados devueltos incluir치n todas las columnas de la tabla de pel칤culas, junto con las columnas de la tabla film_category para cada par de film_id coincidentes en ambas tablas. Tenga en cuenta que la tabla film_category solo incluye el category_id, pero no el nombre de la categor칤a. Por lo tanto, necesitamos hacer otra combinaci칩n para combinar estos registros con las filas de la tabla de categor칤as en funci칩n de los category_id. A침adir칠 la categor칤a JOIN ON film_category.category _id = category.category_id. Ahora los resultados incluir치n todas las columnas de la tabla de pel칤culas, todas las columnas de la tabla film_category y todas las columnas de la tabla de categor칤as. Como solo quiero el t칤tulo de la pel칤cula y la categor칤a de pel칤cula correspondiente, puedo modificar la instrucci칩n SELECT para especificar que solo quiero la columna film.title en la columna category.name. Tenga en cuenta que, de forma predeterminada, la cl치usula JOIN combina solo los registros de ambas tablas que tienen un valor de columna coincidente especificado en la instrucci칩n ON. No incluir치 ning칰n registro de ninguna de las tablas que no tenga valores coincidentes. Por ejemplo, si la tabla de pel칤culas tiene una fila con film_id que no aparece en la tabla film_category, esa fila no se incluir치 en los resultados. Este tipo de uni칩n tambi칠n se conoce como INNER JOIN, y puede pensar en los resultados de la uni칩n como la parte central superpuesta de un diagrama de Venn. Los otros tipos de combinaciones incluyen LEFT JOIN, que devuelve todos los registros de la primera tabla, junto con los registros coincidentes de la segunda tabla, RIGHT JOIN, que devuelve todos los registros de la segunda tabla, junto con los registros coincidentes de la primera tabla, y FULL JOIN, que devuelve todos los registros de ambas tablas y combina los que tienen valores coincidentes. Volviendo a los resultados de la 칰ltima consulta, puedo ver que bastantes de los cortometrajes pertenecen a la categor칤a infantil o documental. Digamos que quiero saber con certeza cu치l es la categor칤a m치s popular de cortometrajes. Puedo usar el comando GROUP BY para agrupar las filas seg칰n la categor칤a_pel칤cula. A continuaci칩n, utilice el comando COUNT para contar el n칰mero de registros de cada una de las categor칤as de pel칤culas. El comando GROUP BY se escribe despu칠s de la cl치usula WHERE. Aqu칤 a침adir칠 GRUPO POR CATEGOR칈A.nombre. Luego modificar칠 la instrucci칩n SELECT para seleccionar category.name y COUNT (*), que cuenta todas las filas de cada categor칤a. Tambi칠n usar칠 el comando AS para dar a la salida de este recuento el nombre de alias film_count. Por 칰ltimo, ordenar칠 los resultados seg칰n el recuento de pel칤culas en orden descendente. Como puede ver, la categor칤a m치s popular para cortometrajes de menos de una hora es la de documental, seguida de acci칩n y luego de ni침os. Estos son algunos de los comandos SQL m치s comunes. Ahora est치 listo para empezar con el laboratorio. El laboratorio tambi칠n cubre algunas operaciones de manipulaci칩n de datos, como CREATE, INSERT INTO, UPDATE y DELETE. Aseg칰rese de leer las instrucciones detenidamente cuando intente cada uno de los ejercicios. Cuando termine el laboratorio, 칰nase a m칤 para echar un vistazo a las bases de datos NoSQL.

Pautas antes de empezar los laboratorios de este curso
Estado: Traducido autom치ticamente del Ingl칠s
Traducido autom치ticamente del Ingl칠s
Informaci칩n:
Este elemento incluye contenido que a칰n no se tradujo a tu idioma preferido.

Por favor, consulte las siguientes indicaciones importantes al iniciar cualquier laboratorio en este curso.

    No utilice una cuenta personal de AWS. Los laboratorios ser치n aprovisionados para usted sin costo alguno en este curso. Si tiene una cuenta personal de AWS, aseg칰rese de cerrar la sesi칩n de esa cuenta antes de comenzar los laboratorios para evitar que se le cobren los servicios de AWS utilizados durante los laboratorios.

    En la medida de lo posible, evite utilizar ordenadores port치tiles proporcionados por la empresa o conectarse a Internet en su lugar de trabajo para trabajar en los laboratorios. Estos pueden tener configuraciones de seguridad que inadvertidamente bloqueen el tr치fico a los recursos que usted utilizar치. Varios alumnos han informado de problemas que no hemos podido reproducir, y la soluci칩n ha sido simplemente cambiar de un port치til de trabajo a un dispositivo personal.

    Si encuentras alg칰n problema con los laboratorios, puedes buscar o crear un tema en esta categor칤a

 en nuestro Foro de la Comunidad. Nuestro personal y nuestros mentores estar치n encantados de ayudarte. 쮸칰n no eres miembro? Puedes hacer clic en este enlace

     para crear tu cuenta gratuita. Si no puedes acceder al laboratorio o a sus recursos, consulta el p치rrafo siguiente.

    Por favor, evita utilizar la opci칩n "Informar de un problema" de Coursera en la parte inferior de la p치gina cuando tengas problemas con los laboratorios. Esto no se controla con tanta frecuencia como el Foro, por lo que la respuesta puede ser m치s lenta.

Problemas para acceder a los laboratorios

Si te encuentras con alguno de los siguientes problemas (enumerados a continuaci칩n) y no puedes acceder al laboratorio, rellena este formulario de google

. Tu cuenta de AWS se actualizar치 en un plazo de 2 d칤as laborables.

Si su problema no es ninguno de los que se indican a continuaci칩n, cree o busque un tema en la plataforma de la Comunidad en lugar de utilizar el formulario (puede hacer clic en este enlace

 para crear su cuenta). Enviar el formulario para otros problemas puede no ayudar a resolverlos.

    El laboratorio se bloquea en la p치gina de carga durante m치s de 20 minutos: intente primero actualizar la p치gina web. Si el problema persiste, rellena el formulario

    .

    El enlace a la consola de AWS est치 vac칤o: En algunos de los laboratorios, se le pedir치 que ejecute este comando para obtener el enlace a la consola de AWS. Si recibes un enlace vac칤o, rellena el formulario

    .

    Si ejecutas un comando en el terminal para obtener el endpoint/direcci칩n de una base de datos u otro recurso y no obtienes ning칰n recurso, por favor rellena el formulario

.

Problemas de formaci칩n de lagos insuficientes (este es un problema temporal en el que estamos trabajando para solucionarlo, pero por ahora rellena el formulario

    ).

Cuando rellenes el formulario, se te guiar치 para que introduzcas la siguiente informaci칩n:

    La direcci칩n de correo electr칩nico de tu cuenta de Coursera y tu nombre de usuario en la comunidad DeepLeaning.IA (Puedes hacer clic en este enlace

     para crear tu cuenta).

    ID del laboratorio: puedes obtener el ID del laboratorio haciendo clic en el signo de interrogaci칩n (ayuda del laboratorio) y luego copiando el ID del laboratorio.

 3.  Si puede acceder al terminal de VS Code, deber치 ejecutar este comando en el terminal:

cat /home/coder/vocapi_logger > vocapi_logger

Este comando crear치 el archivo vocapi_logger que contiene la informaci칩n de registro. Tendr치s que copiar el texto de este archivo y pegarlo en el lugar correspondiente del formulario.

